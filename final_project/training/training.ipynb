{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9231d737",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:40.545300Z",
     "iopub.status.busy": "2023-05-02T13:35:40.544880Z",
     "iopub.status.idle": "2023-05-02T13:35:43.638226Z",
     "shell.execute_reply": "2023-05-02T13:35:43.636890Z"
    },
    "papermill": {
     "duration": 3.101989,
     "end_time": "2023-05-02T13:35:43.641403",
     "exception": false,
     "start_time": "2023-05-02T13:35:40.539414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import datasets, models, transforms, utils\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf2f24d3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:43.651832Z",
     "iopub.status.busy": "2023-05-02T13:35:43.651066Z",
     "iopub.status.idle": "2023-05-02T13:35:43.657454Z",
     "shell.execute_reply": "2023-05-02T13:35:43.655968Z"
    },
    "papermill": {
     "duration": 0.014636,
     "end_time": "2023-05-02T13:35:43.660015",
     "exception": false,
     "start_time": "2023-05-02T13:35:43.645379",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TRAIN_PATH = \"./captcha-hacker-2023-spring/dataset/train\"\n",
    "TEST_PATH = \"./captcha-hacker-2023-spring/dataset/test\"\n",
    "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df32331f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:43.670351Z",
     "iopub.status.busy": "2023-05-02T13:35:43.669920Z",
     "iopub.status.idle": "2023-05-02T13:35:43.676759Z",
     "shell.execute_reply": "2023-05-02T13:35:43.675413Z"
    },
    "papermill": {
     "duration": 0.015331,
     "end_time": "2023-05-02T13:35:43.679636",
     "exception": false,
     "start_time": "2023-05-02T13:35:43.664305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "alphabets = \"abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789\"\n",
    "alphabets2index = {alphabet:i for i, alphabet in enumerate(alphabets)}\n",
    "alphabets_length = len(alphabets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3c078956",
   "metadata": {},
   "outputs": [],
   "source": [
    "#one hot encode\n",
    "def one_hot_encoding(alphabet):\n",
    "    one_hot_vector = np.zeros(alphabets_length)\n",
    "    idx = alphabets2index[alphabet]\n",
    "    one_hot_vector[idx] = 1\n",
    "    return one_hot_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8f28c646",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:43.689981Z",
     "iopub.status.busy": "2023-05-02T13:35:43.688756Z",
     "iopub.status.idle": "2023-05-02T13:35:43.698376Z",
     "shell.execute_reply": "2023-05-02T13:35:43.697256Z"
    },
    "papermill": {
     "duration": 0.017827,
     "end_time": "2023-05-02T13:35:43.701316",
     "exception": false,
     "start_time": "2023-05-02T13:35:43.683489",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "##dataset1\n",
    "class Task1Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False,mode = \"train\"):\n",
    "        self.data = [sample for sample in data if sample[0].startswith(\"task1\")]\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.train_transform = transforms.Compose([\n",
    "                transforms.Resize([224, 224]),\n",
    "                #transforms.RandomResizedCrop(size = (224, 224),scale=(0.98, 1.0)),\n",
    "                transforms.ToTensor()])\n",
    "        self.test_transform = transforms.Compose([\n",
    "                transforms.Resize([224, 224]),\n",
    "                transforms.ToTensor()])\n",
    "        \n",
    "        self.mode = \"train\"\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img = Image.open(f\"{self.root}/{filename}\")\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            img = self.train_transform(img)\n",
    "        else:\n",
    "            img = self.test_transform(img)\n",
    "        \n",
    "        label_all = np.zeros(alphabets_length)\n",
    "        for index, a in enumerate(label):\n",
    "            label_all = one_hot_encoding(a)\n",
    "                \n",
    "        if self.return_filename:\n",
    "            return img, filename\n",
    "        else:\n",
    "            return img, label_all\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "##dataset2\n",
    "class Task2Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False,mode = \"train\"):\n",
    "        self.data = [sample for sample in data if sample[0].startswith(\"task2\")]\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.train_transform = transforms.Compose([\n",
    "                transforms.Resize([224, 224]),\n",
    "                #transforms.RandomResizedCrop(size = (224, 224),scale=(0.98, 1.0)),\n",
    "                transforms.ToTensor()])\n",
    "        self.test_transform = transforms.Compose([\n",
    "                transforms.Resize([224, 224]),\n",
    "                transforms.ToTensor()])\n",
    "        \n",
    "        self.mode = \"train\"\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img = Image.open(f\"{self.root}/{filename}\")\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            img = self.train_transform(img)\n",
    "        else:\n",
    "            img = self.test_transform(img)\n",
    "        \n",
    "        label_all = np.zeros((alphabets_length,2))\n",
    "        for index, a in enumerate(label):\n",
    "            label_all[:,index] = one_hot_encoding(a)\n",
    "                \n",
    "        if self.return_filename:\n",
    "            return img, filename\n",
    "        else:\n",
    "            return img, np.reshape(label_all,-1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "##dataset3\n",
    "class Task3Dataset(Dataset):\n",
    "    def __init__(self, data, root, return_filename=False,mode = \"train\"):\n",
    "        self.data = [sample for sample in data if sample[0].startswith(\"task3\")]\n",
    "        self.return_filename = return_filename\n",
    "        self.root = root\n",
    "        self.train_transform = transforms.Compose([\n",
    "                transforms.Resize([224, 224]),\n",
    "                #transforms.RandomResizedCrop(size = (224, 224),scale=(0.98, 1.0)),\n",
    "                transforms.ToTensor()])\n",
    "        self.test_transform = transforms.Compose([\n",
    "                transforms.Resize([224, 224]),\n",
    "                transforms.ToTensor()])\n",
    "        \n",
    "        self.mode = \"train\"\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        filename, label = self.data[index]\n",
    "        img = Image.open(f\"{self.root}/{filename}\")\n",
    "        \n",
    "        if self.mode == \"train\":\n",
    "            img = self.train_transform(img)\n",
    "        else:\n",
    "            img = self.test_transform(img)\n",
    "        \n",
    "        label_all = np.zeros((alphabets_length,4))\n",
    "        for index, a in enumerate(label):\n",
    "            label_all[:,index] = one_hot_encoding(a)\n",
    "                \n",
    "        if self.return_filename:\n",
    "            return img, filename\n",
    "        else:\n",
    "            return img, np.reshape(label_all,-1)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a4151ecb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:43.732379Z",
     "iopub.status.busy": "2023-05-02T13:35:43.731429Z",
     "iopub.status.idle": "2023-05-02T13:35:43.757472Z",
     "shell.execute_reply": "2023-05-02T13:35:43.756444Z"
    },
    "papermill": {
     "duration": 0.034602,
     "end_time": "2023-05-02T13:35:43.760542",
     "exception": false,
     "start_time": "2023-05-02T13:35:43.725940",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#hyperparameter\n",
    "batch_size = 32\n",
    "\n",
    "train_data = []\n",
    "val_data = []\n",
    "\n",
    "with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:\n",
    "    for row in csv.reader(csvfile, delimiter=','):\n",
    "        if random.random() < 1.5:\n",
    "            train_data.append(row)\n",
    "        else:\n",
    "            val_data.append(row)\n",
    "\n",
    "train_ds = Task1Dataset(train_data, root=TRAIN_PATH, mode = \"train\")\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "\n",
    "val_ds = Task1Dataset(val_data, root=TRAIN_PATH,mode = \"val\")\n",
    "val_dl = DataLoader(val_ds, batch_size=1, drop_last=False, shuffle=False)\n",
    "\n",
    "train_ds_2 = Task2Dataset(train_data, root=TRAIN_PATH, mode = \"train\")\n",
    "train_dl_2 = DataLoader(train_ds_2, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "\n",
    "val_ds_2 = Task2Dataset(val_data, root=TRAIN_PATH,mode = \"val\")\n",
    "val_dl_2 = DataLoader(val_ds_2, batch_size=1, drop_last=False, shuffle=False)\n",
    "\n",
    "train_ds_3 = Task3Dataset(train_data, root=TRAIN_PATH, mode = \"train\")\n",
    "train_dl_3 = DataLoader(train_ds_3, batch_size=batch_size, drop_last=True, shuffle=True)\n",
    "\n",
    "val_ds_3 = Task3Dataset(val_data, root=TRAIN_PATH,mode = \"val\")\n",
    "val_dl_3 = DataLoader(val_ds_3, batch_size=1, drop_last=False, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0241d66f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:43.711580Z",
     "iopub.status.busy": "2023-05-02T13:35:43.710438Z",
     "iopub.status.idle": "2023-05-02T13:35:43.719108Z",
     "shell.execute_reply": "2023-05-02T13:35:43.717803Z"
    },
    "papermill": {
     "duration": 0.016827,
     "end_time": "2023-05-02T13:35:43.722026",
     "exception": false,
     "start_time": "2023-05-02T13:35:43.705199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, Layer=18, word_count=1,Pretrained=True):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.word_count = word_count\n",
    "        \n",
    "        if Layer==18:\n",
    "            self.classify = nn.Linear(512, alphabets_length * word_count)\n",
    "        if Layer==50:\n",
    "            self.classify = nn.Linear(2048, alphabets_length * word_count)\n",
    "        \n",
    "        pretrained_model = torchvision.models.__dict__['resnet{}'.format(Layer)](pretrained=Pretrained)\n",
    "        self.conv1 = pretrained_model._modules['conv1']\n",
    "        self.bn1 = pretrained_model._modules['bn1']\n",
    "        self.relu = pretrained_model._modules['relu']\n",
    "        self.maxpool = pretrained_model._modules['maxpool']\n",
    "\n",
    "        self.layer1 = pretrained_model._modules['layer1']\n",
    "        self.layer2 = pretrained_model._modules['layer2']\n",
    "        self.layer3 = pretrained_model._modules['layer3']\n",
    "        self.layer4 = pretrained_model._modules['layer4']\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        del pretrained_model\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "\n",
    "        x = self.avgpool(x)\n",
    "        # print(x.shape)\n",
    "        x = torch.flatten(x,start_dim=1)\n",
    "        \n",
    "        x = self.classify(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d35ba5f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_paremeter_requires_grads(layer,is_required):\n",
    "    if is_required:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = True\n",
    "    else:\n",
    "        for param in layer.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "def append_model_grad(model_grad,model):\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad == True:\n",
    "            model_grad.append(param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f5254c55",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-05-02T13:35:43.770727Z",
     "iopub.status.busy": "2023-05-02T13:35:43.769493Z",
     "iopub.status.idle": "2023-05-02T13:36:43.805329Z",
     "shell.execute_reply": "2023-05-02T13:36:43.802741Z"
    },
    "papermill": {
     "duration": 60.043917,
     "end_time": "2023-05-02T13:36:43.808305",
     "exception": false,
     "start_time": "2023-05-02T13:35:43.764388",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "loss:  tensor(263.9333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [1]\n",
      "loss:  tensor(224.1207, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [2]\n",
      "loss:  tensor(187.9024, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [3]\n",
      "loss:  tensor(157.4590, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [4]\n",
      "loss:  tensor(128.9881, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [5]\n",
      "loss:  tensor(110.7874, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [6]\n",
      "loss:  tensor(91.2885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [7]\n",
      "loss:  tensor(79.4662, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [8]\n",
      "loss:  tensor(69.6095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [9]\n",
      "loss:  tensor(60.0956, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [10]\n",
      "loss:  tensor(52.2927, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [11]\n",
      "loss:  tensor(15.4822, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [12]\n",
      "loss:  tensor(14.1144, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [13]\n",
      "loss:  tensor(11.6651, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [14]\n",
      "loss:  tensor(4.1509, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [15]\n",
      "loss:  tensor(5.4148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [16]\n",
      "loss:  tensor(4.6871, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [17]\n",
      "loss:  tensor(8.8965, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [18]\n",
      "loss:  tensor(5.0299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [19]\n",
      "loss:  tensor(2.3253, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [20]\n",
      "loss:  tensor(1.4160, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [21]\n",
      "loss:  tensor(2.3604, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [22]\n",
      "loss:  tensor(1.5987, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [23]\n",
      "loss:  tensor(7.1363, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [24]\n",
      "loss:  tensor(6.1579, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [25]\n",
      "loss:  tensor(1.5618, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [26]\n",
      "loss:  tensor(4.0454, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [27]\n",
      "loss:  tensor(2.9149, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [28]\n",
      "loss:  tensor(0.5304, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [29]\n",
      "loss:  tensor(0.1286, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [30]\n",
      "loss:  tensor(0.0672, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [31]\n",
      "loss:  tensor(0.0422, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [32]\n",
      "loss:  tensor(0.0335, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [33]\n",
      "loss:  tensor(0.0272, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [34]\n",
      "loss:  tensor(0.0227, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [35]\n",
      "loss:  tensor(0.0223, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [36]\n",
      "loss:  tensor(0.0232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [37]\n",
      "loss:  tensor(0.0198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [38]\n",
      "loss:  tensor(0.0162, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [39]\n",
      "loss:  tensor(0.0148, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [40]\n",
      "loss:  tensor(0.0151, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [41]\n",
      "loss:  tensor(0.0139, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [42]\n",
      "loss:  tensor(0.0116, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [43]\n",
      "loss:  tensor(0.0137, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [44]\n",
      "loss:  tensor(0.0109, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [45]\n",
      "loss:  tensor(0.0102, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [46]\n",
      "loss:  tensor(0.0100, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [47]\n",
      "loss:  tensor(0.0099, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [48]\n",
      "loss:  tensor(0.0103, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [49]\n",
      "loss:  tensor(0.0079, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [50]\n",
      "loss:  tensor(0.0078, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [51]\n",
      "loss:  tensor(0.0089, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [52]\n",
      "loss:  tensor(0.0091, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [53]\n",
      "loss:  tensor(0.0072, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [54]\n",
      "loss:  tensor(0.0066, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [55]\n",
      "loss:  tensor(0.0065, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [56]\n",
      "loss:  tensor(0.0077, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [57]\n",
      "loss:  tensor(0.0064, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [58]\n",
      "loss:  tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [59]\n",
      "loss:  tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [60]\n",
      "loss:  tensor(0.0051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [61]\n",
      "loss:  tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [62]\n",
      "loss:  tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [63]\n",
      "loss:  tensor(0.0046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [64]\n",
      "loss:  tensor(0.0038, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [65]\n",
      "loss:  tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [66]\n",
      "loss:  tensor(0.0042, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [67]\n",
      "loss:  tensor(0.0035, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [68]\n",
      "loss:  tensor(0.0037, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [69]\n",
      "loss:  tensor(0.0039, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [70]\n",
      "loss:  tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [71]\n",
      "loss:  tensor(0.0034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [72]\n",
      "loss:  tensor(0.0040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [73]\n",
      "loss:  tensor(0.0034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [74]\n",
      "loss:  tensor(0.0028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [75]\n",
      "loss:  tensor(0.0024, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [76]\n",
      "loss:  tensor(0.0023, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [77]\n",
      "loss:  tensor(0.0027, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [78]\n",
      "loss:  tensor(0.0028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [79]\n",
      "loss:  tensor(0.0027, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [80]\n",
      "loss:  tensor(0.0025, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [81]\n",
      "loss:  tensor(0.0025, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [82]\n",
      "loss:  tensor(0.0020, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [83]\n",
      "loss:  tensor(0.0022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [84]\n",
      "loss:  tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [85]\n",
      "loss:  tensor(0.0021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [86]\n",
      "loss:  tensor(0.0018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [87]\n",
      "loss:  tensor(0.0018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [88]\n",
      "loss:  tensor(0.0022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [89]\n",
      "loss:  tensor(0.0017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [90]\n",
      "loss:  tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [91]\n",
      "loss:  tensor(0.0017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [92]\n",
      "loss:  tensor(0.0015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [93]\n",
      "loss:  tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [94]\n",
      "loss:  tensor(0.0017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [95]\n",
      "loss:  tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [96]\n",
      "loss:  tensor(0.0015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [97]\n",
      "loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [98]\n",
      "loss:  tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [99]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [100]\n",
      "loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [101]\n",
      "loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [102]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [103]\n",
      "loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [104]\n",
      "loss:  tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [105]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [106]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [107]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [108]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [109]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [110]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [111]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [112]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [113]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [114]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [115]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [116]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [117]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [118]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [119]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [120]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [121]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [122]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [123]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [124]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [125]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [126]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [127]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [128]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [129]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [130]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [131]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [132]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [133]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [134]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [135]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [136]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [137]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [138]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [139]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [140]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [141]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [142]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [143]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [144]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [145]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [146]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [147]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [148]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [149]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [150]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [151]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [152]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [153]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [154]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [155]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [156]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [157]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [158]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [159]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [160]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [161]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [162]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [163]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [164]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [165]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [166]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [167]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [168]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [169]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [170]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [171]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [172]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [173]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [174]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [175]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [176]\n",
      "loss:  tensor(9.3873e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [177]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [178]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [179]\n",
      "loss:  tensor(8.4791e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [180]\n",
      "loss:  tensor(6.6869e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [181]\n",
      "loss:  tensor(7.9880e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [182]\n",
      "loss:  tensor(9.1030e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [183]\n",
      "loss:  tensor(7.2796e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [184]\n",
      "loss:  tensor(8.3841e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [185]\n",
      "loss:  tensor(8.6042e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [186]\n",
      "loss:  tensor(8.9127e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [187]\n",
      "loss:  tensor(6.2249e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [188]\n",
      "loss:  tensor(7.8298e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [189]\n",
      "loss:  tensor(8.0343e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [190]\n",
      "loss:  tensor(6.6146e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [191]\n",
      "loss:  tensor(7.0891e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [192]\n",
      "loss:  tensor(5.9437e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [193]\n",
      "loss:  tensor(7.0191e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [194]\n",
      "loss:  tensor(5.0913e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [195]\n",
      "loss:  tensor(4.6253e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [196]\n",
      "loss:  tensor(4.5962e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [197]\n",
      "loss:  tensor(6.1279e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [198]\n",
      "loss:  tensor(6.4193e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [199]\n",
      "loss:  tensor(5.5693e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [200]\n",
      "loss:  tensor(4.3898e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [201]\n",
      "loss:  tensor(4.5191e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [202]\n",
      "loss:  tensor(4.5959e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [203]\n",
      "loss:  tensor(4.0166e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [204]\n",
      "loss:  tensor(4.2680e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [205]\n",
      "loss:  tensor(4.9874e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [206]\n",
      "loss:  tensor(3.1363e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [207]\n",
      "loss:  tensor(3.1941e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [208]\n",
      "loss:  tensor(3.6038e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [209]\n",
      "loss:  tensor(7.8544e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [210]\n",
      "loss:  tensor(6.4355e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [211]\n",
      "loss:  tensor(107.4231, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [212]\n",
      "loss:  tensor(59.3208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [213]\n",
      "loss:  tensor(22.1757, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [214]\n",
      "loss:  tensor(13.3326, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [215]\n",
      "loss:  tensor(9.4859, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [216]\n",
      "loss:  tensor(5.5683, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [217]\n",
      "loss:  tensor(4.6570, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [218]\n",
      "loss:  tensor(4.0079, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [219]\n",
      "loss:  tensor(1.5490, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [220]\n",
      "loss:  tensor(1.9043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [221]\n",
      "loss:  tensor(0.6746, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [222]\n",
      "loss:  tensor(1.0994, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [223]\n",
      "loss:  tensor(1.1983, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [224]\n",
      "loss:  tensor(0.7324, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [225]\n",
      "loss:  tensor(0.7689, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [226]\n",
      "loss:  tensor(4.2897, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [227]\n",
      "loss:  tensor(3.6050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [228]\n",
      "loss:  tensor(5.3438, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [229]\n",
      "loss:  tensor(6.9367, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [230]\n",
      "loss:  tensor(2.1804, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [231]\n",
      "loss:  tensor(0.9346, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [232]\n",
      "loss:  tensor(0.8944, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [233]\n",
      "loss:  tensor(2.4921, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [234]\n",
      "loss:  tensor(2.4770, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [235]\n",
      "loss:  tensor(3.4256, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [236]\n",
      "loss:  tensor(1.5452, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [237]\n",
      "loss:  tensor(0.3720, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [238]\n",
      "loss:  tensor(0.6784, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [239]\n",
      "loss:  tensor(1.3435, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [240]\n",
      "loss:  tensor(0.5830, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [241]\n",
      "loss:  tensor(0.0972, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [242]\n",
      "loss:  tensor(0.0622, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [243]\n",
      "loss:  tensor(0.0497, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [244]\n",
      "loss:  tensor(0.0441, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [245]\n",
      "loss:  tensor(0.0382, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [246]\n",
      "loss:  tensor(0.0241, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [247]\n",
      "loss:  tensor(0.2953, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [248]\n",
      "loss:  tensor(2.3563, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [249]\n",
      "loss:  tensor(4.4354, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [250]\n",
      "loss:  tensor(4.1958, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [251]\n",
      "loss:  tensor(4.9156, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [252]\n",
      "loss:  tensor(3.0305, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [253]\n",
      "loss:  tensor(1.8021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [254]\n",
      "loss:  tensor(1.8890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [255]\n",
      "loss:  tensor(1.5235, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [256]\n",
      "loss:  tensor(0.3854, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [257]\n",
      "loss:  tensor(0.2985, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [258]\n",
      "loss:  tensor(0.3497, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [259]\n",
      "loss:  tensor(0.3890, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [260]\n",
      "loss:  tensor(0.2778, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [261]\n",
      "loss:  tensor(0.1080, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [262]\n",
      "loss:  tensor(0.0340, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [263]\n",
      "loss:  tensor(0.0249, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [264]\n",
      "loss:  tensor(0.0365, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [265]\n",
      "loss:  tensor(0.0276, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [266]\n",
      "loss:  tensor(0.0182, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [267]\n",
      "loss:  tensor(0.0192, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [268]\n",
      "loss:  tensor(0.0119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [269]\n",
      "loss:  tensor(0.0126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [270]\n",
      "loss:  tensor(0.0122, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [271]\n",
      "loss:  tensor(0.0079, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [272]\n",
      "loss:  tensor(0.0107, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [273]\n",
      "loss:  tensor(0.0098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [274]\n",
      "loss:  tensor(0.0069, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [275]\n",
      "loss:  tensor(0.0092, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [276]\n",
      "loss:  tensor(0.0068, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [277]\n",
      "loss:  tensor(0.0057, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [278]\n",
      "loss:  tensor(0.0083, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [279]\n",
      "loss:  tensor(0.0076, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [280]\n",
      "loss:  tensor(0.0126, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [281]\n",
      "loss:  tensor(0.0076, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [282]\n",
      "loss:  tensor(0.0089, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [283]\n",
      "loss:  tensor(0.0062, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [284]\n",
      "loss:  tensor(0.0053, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [285]\n",
      "loss:  tensor(0.0055, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [286]\n",
      "loss:  tensor(0.0071, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [287]\n",
      "loss:  tensor(0.0047, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [288]\n",
      "loss:  tensor(0.0041, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [289]\n",
      "loss:  tensor(0.0038, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [290]\n",
      "loss:  tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [291]\n",
      "loss:  tensor(0.0044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [292]\n",
      "loss:  tensor(0.0031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [293]\n",
      "loss:  tensor(0.0037, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [294]\n",
      "loss:  tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [295]\n",
      "loss:  tensor(0.0033, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [296]\n",
      "loss:  tensor(0.0048, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [297]\n",
      "loss:  tensor(0.0031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [298]\n",
      "loss:  tensor(0.0027, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [299]\n",
      "loss:  tensor(0.0029, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'        \\n    sample_count = 0\\n    correct_count = 0\\n    model.eval()\\n    \\n    for image, label in val_dl:\\n        image = image.to(device)\\n        label = label.to(device)\\n        \\n        pred = model(image)\\n        loss = loss_fn(pred, label)\\n        pred = torch.argmax(pred, dim=1)\\n        label_argmax = torch.argmax(label, dim=1)\\n\\n        sample_count += len(image)\\n        correct_count += (label_argmax == pred)\\n        \\n    print(\"accuracy (validation):\", correct_count / sample_count)\\n'"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = ResNet(Layer=50,word_count=1).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=7e-4)\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "min_loss = 999999999999999\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #pretrained\n",
    "    ct = 0\n",
    "    model_grad=[]\n",
    "    \n",
    "    for children in model.children():\n",
    "        ct += 1\n",
    "        if (ct > 2) & (epoch<10):\n",
    "            set_paremeter_requires_grads(children,0)\n",
    "        else:\n",
    "            set_paremeter_requires_grads(children,1)   \n",
    "            \n",
    "    append_model_grad(model_grad,model)\n",
    "        \n",
    "    print(f\"Epoch [{epoch}]\")\n",
    "    model.train()\n",
    "    sum_loss = 0\n",
    "    for image, label in train_dl:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        pred = model(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        sum_loss += loss  \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"loss: \",sum_loss)\n",
    "    if min_loss > sum_loss:\n",
    "        min_loss = sum_loss\n",
    "        torch.save(model.state_dict(), \"Task1_model_all3\")\n",
    "'''        \n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    model.eval()\n",
    "    \n",
    "    for image, label in val_dl:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        pred = model(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        pred = torch.argmax(pred, dim=1)\n",
    "        label_argmax = torch.argmax(label, dim=1)\n",
    "\n",
    "        sample_count += len(image)\n",
    "        correct_count += (label_argmax == pred)\n",
    "        \n",
    "    print(\"accuracy (validation):\", correct_count / sample_count)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "40a624d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "loss:  tensor(8.3506, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [1]\n",
      "loss:  tensor(6.4151, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [2]\n",
      "loss:  tensor(6.1616, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [3]\n",
      "loss:  tensor(5.8396, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [4]\n",
      "loss:  tensor(5.4959, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [5]\n",
      "loss:  tensor(5.1462, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [6]\n",
      "loss:  tensor(4.8552, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [7]\n",
      "loss:  tensor(4.6116, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [8]\n",
      "loss:  tensor(4.4101, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [9]\n",
      "loss:  tensor(4.1917, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [10]\n",
      "loss:  tensor(3.1795, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [11]\n",
      "loss:  tensor(1.0309, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [12]\n",
      "loss:  tensor(0.5734, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [13]\n",
      "loss:  tensor(0.3889, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [14]\n",
      "loss:  tensor(0.3292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [15]\n",
      "loss:  tensor(0.2812, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [16]\n",
      "loss:  tensor(0.3348, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [17]\n",
      "loss:  tensor(0.3023, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [18]\n",
      "loss:  tensor(0.1718, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [19]\n",
      "loss:  tensor(0.2100, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [20]\n",
      "loss:  tensor(0.2516, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [21]\n",
      "loss:  tensor(0.1731, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [22]\n",
      "loss:  tensor(0.1408, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [23]\n",
      "loss:  tensor(0.0767, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [24]\n",
      "loss:  tensor(0.0857, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [25]\n",
      "loss:  tensor(0.1003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [26]\n",
      "loss:  tensor(0.1093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [27]\n",
      "loss:  tensor(0.0872, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [28]\n",
      "loss:  tensor(0.0394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [29]\n",
      "loss:  tensor(0.0217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [30]\n",
      "loss:  tensor(0.0133, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [31]\n",
      "loss:  tensor(0.0119, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [32]\n",
      "loss:  tensor(0.0061, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [33]\n",
      "loss:  tensor(0.0044, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [34]\n",
      "loss:  tensor(0.0035, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [35]\n",
      "loss:  tensor(0.0031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [36]\n",
      "loss:  tensor(0.0029, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [37]\n",
      "loss:  tensor(0.0030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [38]\n",
      "loss:  tensor(0.0025, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [39]\n",
      "loss:  tensor(0.0023, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [40]\n",
      "loss:  tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [41]\n",
      "loss:  tensor(0.0020, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [42]\n",
      "loss:  tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [43]\n",
      "loss:  tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [44]\n",
      "loss:  tensor(0.0015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [45]\n",
      "loss:  tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [46]\n",
      "loss:  tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [47]\n",
      "loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [48]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [49]\n",
      "loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [50]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [51]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [52]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [53]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [54]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [55]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [56]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [57]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [58]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [59]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [60]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [61]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [62]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [63]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [64]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [65]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [66]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [67]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [68]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [69]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [70]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [71]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [72]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [73]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [74]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [75]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [76]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [77]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [78]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [79]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [80]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [81]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [82]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [83]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [84]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [85]\n",
      "loss:  tensor(2.8386, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [86]\n",
      "loss:  tensor(1.2813, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [87]\n",
      "loss:  tensor(0.3895, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [88]\n",
      "loss:  tensor(0.1885, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [89]\n",
      "loss:  tensor(0.1623, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [90]\n",
      "loss:  tensor(0.1518, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [91]\n",
      "loss:  tensor(0.0839, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [92]\n",
      "loss:  tensor(0.0406, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [93]\n",
      "loss:  tensor(0.0302, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [94]\n",
      "loss:  tensor(0.0668, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [95]\n",
      "loss:  tensor(0.0556, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [96]\n",
      "loss:  tensor(0.0772, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [97]\n",
      "loss:  tensor(0.0998, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [98]\n",
      "loss:  tensor(0.1276, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [99]\n",
      "loss:  tensor(0.1050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [100]\n",
      "loss:  tensor(0.0805, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [101]\n",
      "loss:  tensor(0.1578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [102]\n",
      "loss:  tensor(0.0679, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [103]\n",
      "loss:  tensor(0.0976, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [104]\n",
      "loss:  tensor(0.0477, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [105]\n",
      "loss:  tensor(0.0349, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [106]\n",
      "loss:  tensor(0.0292, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [107]\n",
      "loss:  tensor(0.0231, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [108]\n",
      "loss:  tensor(0.0174, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [109]\n",
      "loss:  tensor(0.0122, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [110]\n",
      "loss:  tensor(0.0086, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [111]\n",
      "loss:  tensor(0.0038, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [112]\n",
      "loss:  tensor(0.0036, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [113]\n",
      "loss:  tensor(0.0027, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [114]\n",
      "loss:  tensor(0.0017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [115]\n",
      "loss:  tensor(0.0015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [116]\n",
      "loss:  tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [117]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [118]\n",
      "loss:  tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [119]\n",
      "loss:  tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [120]\n",
      "loss:  tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [121]\n",
      "loss:  tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [122]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [123]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [124]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [125]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [126]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [127]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [128]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [129]\n",
      "loss:  tensor(0.0467, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [130]\n",
      "loss:  tensor(0.6634, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [131]\n",
      "loss:  tensor(0.2674, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [132]\n",
      "loss:  tensor(0.0836, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [133]\n",
      "loss:  tensor(0.0591, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [134]\n",
      "loss:  tensor(0.0308, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [135]\n",
      "loss:  tensor(0.0158, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [136]\n",
      "loss:  tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [137]\n",
      "loss:  tensor(0.0025, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [138]\n",
      "loss:  tensor(0.0034, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [139]\n",
      "loss:  tensor(0.0050, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [140]\n",
      "loss:  tensor(0.0065, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [141]\n",
      "loss:  tensor(0.0659, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [142]\n",
      "loss:  tensor(0.0240, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [143]\n",
      "loss:  tensor(0.0492, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [144]\n",
      "loss:  tensor(0.0808, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [145]\n",
      "loss:  tensor(0.1020, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [146]\n",
      "loss:  tensor(0.0377, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [147]\n",
      "loss:  tensor(0.0342, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [148]\n",
      "loss:  tensor(0.0419, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [149]\n",
      "loss:  tensor(0.0277, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [150]\n",
      "loss:  tensor(0.0054, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [151]\n",
      "loss:  tensor(0.0026, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [152]\n",
      "loss:  tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [153]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [154]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [155]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [156]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [157]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [158]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [159]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [160]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [161]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [162]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [163]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [164]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [165]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [166]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [167]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [168]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [169]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [170]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [171]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [172]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [173]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [174]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [175]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [176]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [177]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [178]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [179]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [180]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [181]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [182]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [183]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [184]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [185]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [186]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [187]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [188]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [189]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [190]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [191]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [192]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [193]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [194]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [195]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [196]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [197]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [198]\n",
      "loss:  tensor(9.4821e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [199]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [200]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [201]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [202]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [203]\n",
      "loss:  tensor(0.2592, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [204]\n",
      "loss:  tensor(0.7312, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [205]\n",
      "loss:  tensor(0.1249, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [206]\n",
      "loss:  tensor(0.0385, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [207]\n",
      "loss:  tensor(0.0236, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [208]\n",
      "loss:  tensor(0.0234, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [209]\n",
      "loss:  tensor(0.0252, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [210]\n",
      "loss:  tensor(0.0173, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [211]\n",
      "loss:  tensor(0.0062, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [212]\n",
      "loss:  tensor(0.0032, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [213]\n",
      "loss:  tensor(0.0093, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [214]\n",
      "loss:  tensor(0.0046, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [215]\n",
      "loss:  tensor(0.0015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [216]\n",
      "loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [217]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [218]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [219]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [220]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [221]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [222]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [223]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [224]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [225]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [226]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [227]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [228]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [229]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [230]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [231]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [232]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [233]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [234]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [235]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [236]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [237]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [238]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [239]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [240]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [241]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [242]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [243]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [244]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [245]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [246]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [247]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [248]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [249]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [250]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [251]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [252]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [253]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [254]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [255]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [256]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [257]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [258]\n",
      "loss:  tensor(9.8395e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [259]\n",
      "loss:  tensor(9.3566e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [260]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [261]\n",
      "loss:  tensor(9.2906e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [262]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [263]\n",
      "loss:  tensor(8.5314e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [264]\n",
      "loss:  tensor(9.6274e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [265]\n",
      "loss:  tensor(7.5168e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [266]\n",
      "loss:  tensor(8.2589e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [267]\n",
      "loss:  tensor(8.1860e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [268]\n",
      "loss:  tensor(8.8335e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [269]\n",
      "loss:  tensor(6.4117e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [270]\n",
      "loss:  tensor(7.5130e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [271]\n",
      "loss:  tensor(7.5400e-05, device='cuda:0', dtype=torch.float64,\n",
      "       grad_fn=<AddBackward0>)\n",
      "Epoch [272]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [273]\n",
      "loss:  tensor(0.0125, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [274]\n",
      "loss:  tensor(0.6225, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [275]\n",
      "loss:  tensor(0.1309, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [276]\n",
      "loss:  tensor(0.0261, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [277]\n",
      "loss:  tensor(0.0071, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [278]\n",
      "loss:  tensor(0.0077, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [279]\n",
      "loss:  tensor(0.0325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [280]\n",
      "loss:  tensor(0.0262, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [281]\n",
      "loss:  tensor(0.0610, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [282]\n",
      "loss:  tensor(0.0433, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [283]\n",
      "loss:  tensor(0.0198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [284]\n",
      "loss:  tensor(0.0333, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [285]\n",
      "loss:  tensor(0.0123, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [286]\n",
      "loss:  tensor(0.0027, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [287]\n",
      "loss:  tensor(0.0049, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [288]\n",
      "loss:  tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [289]\n",
      "loss:  tensor(0.0018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [290]\n",
      "loss:  tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [291]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [292]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [293]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [294]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [295]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [296]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [297]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [298]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [299]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    \\n    sample_count = 0\\n    correct_count = 0\\n    model_2.eval()\\n    \\n    for image, label in val_dl_2:\\n        image = image.to(device)\\n        label = label.to(device)\\n        \\n        pred = model_2(image)\\n        loss = loss_fn(pred, label)\\n        \\n        pred = torch.reshape(pred,(-1,2))\\n        label = torch.reshape(label,(-1,2))\\n\\n        label_argmax = torch.argmax(label,dim = 0)\\n        pred_argmax = torch.argmax(pred,dim = 0)\\n\\n        sample_count += len(image)\\n        correct_count += torch.equal(label_argmax,pred_argmax)\\n        \\n    print(\"accuracy (validation):\", correct_count / sample_count)\\n'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model_2 = ResNet(Layer=50,word_count=2).to(device)\n",
    "optimizer = torch.optim.Adam(model_2.parameters(), lr=7e-4)\n",
    "loss_fn = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "min_loss = 999999999999999\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #pretrained\n",
    "    ct = 0\n",
    "    model_2_grad=[]\n",
    "    \n",
    "    for children in model_2.children():\n",
    "        ct += 1\n",
    "        if (ct > 2) & (epoch<10):\n",
    "            set_paremeter_requires_grads(children,0)\n",
    "        else:\n",
    "            set_paremeter_requires_grads(children,1)   \n",
    "            \n",
    "    append_model_grad(model_2_grad,model_2)\n",
    "        \n",
    "    print(f\"Epoch [{epoch}]\")\n",
    "    model_2.train()\n",
    "    sum_loss = 0\n",
    "    for image, label in train_dl_2:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        pred = model_2(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        sum_loss += loss  \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"loss: \",sum_loss)\n",
    "    if min_loss > sum_loss:\n",
    "        min_loss = sum_loss\n",
    "        torch.save(model_2.state_dict(), \"Task2_model_all3\")\n",
    "'''    \n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    model_2.eval()\n",
    "    \n",
    "    for image, label in val_dl_2:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        pred = model_2(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        \n",
    "        pred = torch.reshape(pred,(-1,2))\n",
    "        label = torch.reshape(label,(-1,2))\n",
    "\n",
    "        label_argmax = torch.argmax(label,dim = 0)\n",
    "        pred_argmax = torch.argmax(pred,dim = 0)\n",
    "\n",
    "        sample_count += len(image)\n",
    "        correct_count += torch.equal(label_argmax,pred_argmax)\n",
    "        \n",
    "    print(\"accuracy (validation):\", correct_count / sample_count)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6feeb154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [0]\n",
      "loss:  tensor(12.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [1]\n",
      "loss:  tensor(9.9670, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [2]\n",
      "loss:  tensor(9.6687, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [3]\n",
      "loss:  tensor(9.3591, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [4]\n",
      "loss:  tensor(9.0318, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [5]\n",
      "loss:  tensor(8.7730, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [6]\n",
      "loss:  tensor(8.5095, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [7]\n",
      "loss:  tensor(8.2898, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [8]\n",
      "loss:  tensor(8.0820, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [9]\n",
      "loss:  tensor(7.8825, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [10]\n",
      "loss:  tensor(6.6196, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [11]\n",
      "loss:  tensor(3.2430, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [12]\n",
      "loss:  tensor(1.6805, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [13]\n",
      "loss:  tensor(0.9821, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [14]\n",
      "loss:  tensor(0.7124, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [15]\n",
      "loss:  tensor(0.4613, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [16]\n",
      "loss:  tensor(0.3459, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [17]\n",
      "loss:  tensor(0.2856, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [18]\n",
      "loss:  tensor(0.2508, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [19]\n",
      "loss:  tensor(0.3080, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [20]\n",
      "loss:  tensor(0.2371, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [21]\n",
      "loss:  tensor(0.1760, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [22]\n",
      "loss:  tensor(0.1752, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [23]\n",
      "loss:  tensor(0.1343, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [24]\n",
      "loss:  tensor(0.1740, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [25]\n",
      "loss:  tensor(0.2581, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [26]\n",
      "loss:  tensor(0.1208, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [27]\n",
      "loss:  tensor(0.1091, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [28]\n",
      "loss:  tensor(0.3288, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [29]\n",
      "loss:  tensor(0.2335, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [30]\n",
      "loss:  tensor(0.1558, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [31]\n",
      "loss:  tensor(0.1330, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [32]\n",
      "loss:  tensor(0.1094, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [33]\n",
      "loss:  tensor(0.0586, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [34]\n",
      "loss:  tensor(0.1212, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [35]\n",
      "loss:  tensor(0.2463, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [36]\n",
      "loss:  tensor(0.1866, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [37]\n",
      "loss:  tensor(0.2112, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [38]\n",
      "loss:  tensor(0.1204, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [39]\n",
      "loss:  tensor(0.0475, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [40]\n",
      "loss:  tensor(0.0261, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [41]\n",
      "loss:  tensor(0.0541, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [42]\n",
      "loss:  tensor(0.2223, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [43]\n",
      "loss:  tensor(0.0931, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [44]\n",
      "loss:  tensor(0.1325, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [45]\n",
      "loss:  tensor(0.0924, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [46]\n",
      "loss:  tensor(0.0805, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [47]\n",
      "loss:  tensor(0.1465, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [48]\n",
      "loss:  tensor(0.0806, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [49]\n",
      "loss:  tensor(0.0968, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [50]\n",
      "loss:  tensor(0.0659, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [51]\n",
      "loss:  tensor(0.0555, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [52]\n",
      "loss:  tensor(0.0754, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [53]\n",
      "loss:  tensor(0.2565, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [54]\n",
      "loss:  tensor(0.1299, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [55]\n",
      "loss:  tensor(0.0636, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [56]\n",
      "loss:  tensor(0.0245, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [57]\n",
      "loss:  tensor(0.0088, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [58]\n",
      "loss:  tensor(0.0042, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [59]\n",
      "loss:  tensor(0.0030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [60]\n",
      "loss:  tensor(0.0021, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [61]\n",
      "loss:  tensor(0.0015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [62]\n",
      "loss:  tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [63]\n",
      "loss:  tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [64]\n",
      "loss:  tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [65]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [66]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [67]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [68]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [69]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [70]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [71]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [72]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [73]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [74]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [75]\n",
      "loss:  tensor(0.2421, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [76]\n",
      "loss:  tensor(1.0394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [77]\n",
      "loss:  tensor(0.1671, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [78]\n",
      "loss:  tensor(0.0628, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [79]\n",
      "loss:  tensor(0.0595, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [80]\n",
      "loss:  tensor(0.0286, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [81]\n",
      "loss:  tensor(0.0166, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [82]\n",
      "loss:  tensor(0.0268, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [83]\n",
      "loss:  tensor(0.0171, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [84]\n",
      "loss:  tensor(0.0578, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [85]\n",
      "loss:  tensor(0.1024, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [86]\n",
      "loss:  tensor(0.1005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [87]\n",
      "loss:  tensor(0.1198, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [88]\n",
      "loss:  tensor(0.0752, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [89]\n",
      "loss:  tensor(0.0398, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [90]\n",
      "loss:  tensor(0.0232, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [91]\n",
      "loss:  tensor(0.0155, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [92]\n",
      "loss:  tensor(0.0251, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [93]\n",
      "loss:  tensor(0.0658, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [94]\n",
      "loss:  tensor(0.0824, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [95]\n",
      "loss:  tensor(0.1039, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [96]\n",
      "loss:  tensor(0.1410, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [97]\n",
      "loss:  tensor(0.0395, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [98]\n",
      "loss:  tensor(0.0200, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [99]\n",
      "loss:  tensor(0.0404, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [100]\n",
      "loss:  tensor(0.0286, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [101]\n",
      "loss:  tensor(0.0182, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [102]\n",
      "loss:  tensor(0.0078, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [103]\n",
      "loss:  tensor(0.0029, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [104]\n",
      "loss:  tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [105]\n",
      "loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [106]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [107]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [108]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [109]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [110]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [111]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [112]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [113]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [114]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [115]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [116]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [117]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [118]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [119]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [120]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [121]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [122]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [123]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [124]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [125]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [126]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [127]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [128]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [129]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [130]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [131]\n",
      "loss:  tensor(0.6646, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [132]\n",
      "loss:  tensor(0.2406, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [133]\n",
      "loss:  tensor(0.0612, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [134]\n",
      "loss:  tensor(0.0221, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [135]\n",
      "loss:  tensor(0.0780, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [136]\n",
      "loss:  tensor(0.0268, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [137]\n",
      "loss:  tensor(0.0080, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [138]\n",
      "loss:  tensor(0.0040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [139]\n",
      "loss:  tensor(0.0017, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [140]\n",
      "loss:  tensor(0.0018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [141]\n",
      "loss:  tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [142]\n",
      "loss:  tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [143]\n",
      "loss:  tensor(0.0019, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [144]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [145]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [146]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [147]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [148]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [149]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [150]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [151]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [152]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [153]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [154]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [155]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [156]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [157]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [158]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [159]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [160]\n",
      "loss:  tensor(0.0155, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [161]\n",
      "loss:  tensor(0.6619, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [162]\n",
      "loss:  tensor(0.1076, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [163]\n",
      "loss:  tensor(0.0237, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [164]\n",
      "loss:  tensor(0.0394, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [165]\n",
      "loss:  tensor(0.0098, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [166]\n",
      "loss:  tensor(0.0043, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [167]\n",
      "loss:  tensor(0.0022, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [168]\n",
      "loss:  tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [169]\n",
      "loss:  tensor(0.0016, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [170]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [171]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [172]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [173]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [174]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [175]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [176]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [177]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [178]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [179]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [180]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [181]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [182]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [183]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [184]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [185]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [186]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [187]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [188]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [189]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [190]\n",
      "loss:  tensor(0.0489, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [191]\n",
      "loss:  tensor(0.4915, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [192]\n",
      "loss:  tensor(0.1258, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [193]\n",
      "loss:  tensor(0.0503, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [194]\n",
      "loss:  tensor(0.0353, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [195]\n",
      "loss:  tensor(0.0291, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [196]\n",
      "loss:  tensor(0.0085, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [197]\n",
      "loss:  tensor(0.0023, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [198]\n",
      "loss:  tensor(0.0014, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [199]\n",
      "loss:  tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [200]\n",
      "loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [201]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [202]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [203]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [204]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [205]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [206]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [207]\n",
      "loss:  tensor(0.0006, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [208]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [209]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [210]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [211]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [212]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [213]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [214]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [215]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [216]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [217]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [218]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [219]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [220]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [221]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [222]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [223]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [224]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [225]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [226]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [227]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [228]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [229]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [230]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [231]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [232]\n",
      "loss:  tensor(0.2916, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [233]\n",
      "loss:  tensor(0.2435, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [234]\n",
      "loss:  tensor(0.0608, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [235]\n",
      "loss:  tensor(0.0150, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [236]\n",
      "loss:  tensor(0.0070, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [237]\n",
      "loss:  tensor(0.0028, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [238]\n",
      "loss:  tensor(0.0015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [239]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [240]\n",
      "loss:  tensor(0.0012, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [241]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [242]\n",
      "loss:  tensor(0.0007, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [243]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [244]\n",
      "loss:  tensor(0.0009, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [245]\n",
      "loss:  tensor(0.0110, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [246]\n",
      "loss:  tensor(0.0858, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [247]\n",
      "loss:  tensor(0.0621, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [248]\n",
      "loss:  tensor(0.0449, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [249]\n",
      "loss:  tensor(0.0136, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [250]\n",
      "loss:  tensor(0.0217, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [251]\n",
      "loss:  tensor(0.0633, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [252]\n",
      "loss:  tensor(0.0536, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [253]\n",
      "loss:  tensor(0.0108, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [254]\n",
      "loss:  tensor(0.0065, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [255]\n",
      "loss:  tensor(0.0051, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [256]\n",
      "loss:  tensor(0.0018, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [257]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [258]\n",
      "loss:  tensor(0.0008, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [259]\n",
      "loss:  tensor(0.0030, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [260]\n",
      "loss:  tensor(0.0040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [261]\n",
      "loss:  tensor(0.0195, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [262]\n",
      "loss:  tensor(0.0190, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [263]\n",
      "loss:  tensor(0.0769, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [264]\n",
      "loss:  tensor(0.0267, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [265]\n",
      "loss:  tensor(0.0125, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [266]\n",
      "loss:  tensor(0.0025, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [267]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [268]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [269]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [270]\n",
      "loss:  tensor(0.0010, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [271]\n",
      "loss:  tensor(0.0005, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [272]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [273]\n",
      "loss:  tensor(0.0004, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [274]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [275]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [276]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [277]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [278]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [279]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [280]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [281]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [282]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [283]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [284]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [285]\n",
      "loss:  tensor(0.0001, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [286]\n",
      "loss:  tensor(0.0002, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [287]\n",
      "loss:  tensor(0.0003, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [288]\n",
      "loss:  tensor(0.1760, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [289]\n",
      "loss:  tensor(0.1031, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [290]\n",
      "loss:  tensor(0.0324, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [291]\n",
      "loss:  tensor(0.0188, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [292]\n",
      "loss:  tensor(0.0122, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [293]\n",
      "loss:  tensor(0.0040, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [294]\n",
      "loss:  tensor(0.0035, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [295]\n",
      "loss:  tensor(0.0015, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [296]\n",
      "loss:  tensor(0.0013, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [297]\n",
      "loss:  tensor(0.0011, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [298]\n",
      "loss:  tensor(0.0145, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n",
      "Epoch [299]\n",
      "loss:  tensor(0.0094, device='cuda:0', dtype=torch.float64, grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'    \\n    sample_count = 0\\n    correct_count = 0\\n    model_3.eval()\\n    \\n    for image, label in val_dl_3:\\n        image = image.to(device)\\n        label = label.to(device)\\n        \\n        pred = model_3(image)\\n        loss = loss_fn(pred, label)\\n        \\n        pred = torch.reshape(pred,(-1,4))\\n        label = torch.reshape(label,(-1,4))\\n\\n        label_argmax = torch.argmax(label,dim = 0)\\n        pred_argmax = torch.argmax(pred,dim = 0)\\n\\n        sample_count += len(image)\\n        correct_count += torch.equal(label_argmax,pred_argmax)\\n        \\n    print(\"accuracy (validation):\", correct_count / sample_count)\\n'"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_3 = ResNet(Layer=50,word_count=4).to(device)\n",
    "optimizer = torch.optim.Adam(model_3.parameters(), lr=7e-4)\n",
    "loss_fn = nn.MultiLabelSoftMarginLoss()\n",
    "\n",
    "epochs = 300\n",
    "\n",
    "min_loss = 999999999999999\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #pretrained\n",
    "    ct = 0\n",
    "    model_3_grad=[]\n",
    "    \n",
    "    for children in model_3.children():\n",
    "        ct += 1\n",
    "        if (ct > 2) & (epoch<10):\n",
    "            set_paremeter_requires_grads(children,0)\n",
    "        else:\n",
    "            set_paremeter_requires_grads(children,1)   \n",
    "            \n",
    "    append_model_grad(model_3_grad,model_3)\n",
    "        \n",
    "    print(f\"Epoch [{epoch}]\")\n",
    "    model_3.train()\n",
    "    sum_loss = 0\n",
    "    for image, label in train_dl_3:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        pred = model_3(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        sum_loss += loss  \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(\"loss: \",sum_loss)\n",
    "    if min_loss > sum_loss:\n",
    "        min_loss = sum_loss\n",
    "        torch.save(model_3.state_dict(), \"Task3_model_all3\")\n",
    "'''    \n",
    "    sample_count = 0\n",
    "    correct_count = 0\n",
    "    model_3.eval()\n",
    "    \n",
    "    for image, label in val_dl_3:\n",
    "        image = image.to(device)\n",
    "        label = label.to(device)\n",
    "        \n",
    "        pred = model_3(image)\n",
    "        loss = loss_fn(pred, label)\n",
    "        \n",
    "        pred = torch.reshape(pred,(-1,4))\n",
    "        label = torch.reshape(label,(-1,4))\n",
    "\n",
    "        label_argmax = torch.argmax(label,dim = 0)\n",
    "        pred_argmax = torch.argmax(pred,dim = 0)\n",
    "\n",
    "        sample_count += len(image)\n",
    "        correct_count += torch.equal(label_argmax,pred_argmax)\n",
    "        \n",
    "    print(\"accuracy (validation):\", correct_count / sample_count)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 92.821945,
   "end_time": "2023-05-02T13:36:52.537973",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-05-02T13:35:19.716028",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

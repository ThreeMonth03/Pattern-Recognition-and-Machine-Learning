# -*- coding: utf-8 -*-
"""0810749_inference_rf.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1HcFm9UduVNCkdXS5PnbVZXT5RllxEG6M
"""

import csv
import cv2
import numpy as np
import random
import os
import pandas as pd
from tqdm import tqdm
from PIL import Image
import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from torchvision import datasets, models, transforms, utils
import torchvision

TRAIN_PATH = "./captcha-hacker-2023-spring/dataset/train"
TEST_PATH = "./captcha-hacker-2023-spring/dataset/test"
device = "cuda:0" if torch.cuda.is_available() else "cpu"
MODEL_PATH = "./Task1_model_all"
MODEL2_PATH = "./Task1_model_all2"
MODEL3_PATH = "./Task1_model_all3"
MODEL4_PATH = "./Task2_model_all"
MODEL5_PATH = "./Task2_model_all2"
MODEL6_PATH = "./Task2_model_all3"
MODEL7_PATH = "./Task3_model_all"
MODEL8_PATH = "./Task3_model_all2"
MODEL9_PATH = "./Task3_model_all3"

alphabets = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789"
alphabets2index = {alphabet:i for i, alphabet in enumerate(alphabets)}
alphabets_length = len(alphabets)

#one hot encode
def one_hot_encoding(alphabet):
    one_hot_vector = np.zeros(alphabets_length)
    idx = alphabets2index[alphabet]
    one_hot_vector[idx] = 1
    return one_hot_vector

##dataset1
class Task1Dataset(Dataset):
    def __init__(self, data, root, return_filename=False,mode = "train"):
        self.data = [sample for sample in data if sample[0].startswith("task1")]
        self.return_filename = return_filename
        self.root = root
        self.train_transform = transforms.Compose([
                transforms.Resize([224, 224]),
                #transforms.RandomResizedCrop(size = (224, 224),scale=(0.98, 1.0)),
                transforms.ToTensor()])
        self.test_transform = transforms.Compose([
                transforms.Resize([224, 224]),
                transforms.ToTensor()])
        
        self.mode = "train"
        
    def __getitem__(self, index):
        filename, label = self.data[index]
        img = Image.open(f"{self.root}/{filename}")
        
        if self.mode == "train":
            img = self.train_transform(img)
        else:
            img = self.test_transform(img)
        
        label_all = np.zeros(alphabets_length)
        for index, a in enumerate(label):
            label_all = one_hot_encoding(a)
                
        if self.return_filename:
            return img, filename
        else:
            return img, label_all
        
    def __len__(self):
        return len(self.data)
##dataset2
class Task2Dataset(Dataset):
    def __init__(self, data, root, return_filename=False,mode = "train"):
        self.data = [sample for sample in data if sample[0].startswith("task2")]
        self.return_filename = return_filename
        self.root = root
        self.train_transform = transforms.Compose([
                transforms.Resize([224, 224]),
                #transforms.RandomResizedCrop(size = (224, 224),scale=(0.98, 1.0)),
                transforms.ToTensor()])
        self.test_transform = transforms.Compose([
                transforms.Resize([224, 224]),
                transforms.ToTensor()])
        
        self.mode = "train"
        
    def __getitem__(self, index):
        filename, label = self.data[index]
        img = Image.open(f"{self.root}/{filename}")
    
        if self.mode == "train":
            img = self.train_transform(img)
        else:
            img = self.test_transform(img)
        
        label_all = np.zeros((alphabets_length,2))
        for index, a in enumerate(label):
            label_all[:,index] = one_hot_encoding(a)
            
        if self.return_filename:
            return img, filename                 

        else:
            return img, np.reshape(label_all,-1)
        
    def __len__(self):
        return len(self.data)

##dataset3
class Task3Dataset(Dataset):
    def __init__(self, data, root, return_filename=False,mode = "train"):
        self.data = [sample for sample in data if sample[0].startswith("task3")]
        self.return_filename = return_filename
        self.root = root
        self.train_transform = transforms.Compose([
                transforms.Resize([224, 224]),
                #transforms.RandomResizedCrop(size = (224, 224),scale=(0.98, 1.0)),
                transforms.ToTensor()])
        self.test_transform = transforms.Compose([
                transforms.Resize([224, 224]),
                transforms.ToTensor()])
        
        self.mode = "train"
        
    def __getitem__(self, index):
        filename, label = self.data[index]
        img = Image.open(f"{self.root}/{filename}")
        
        if self.mode == "train":
            img = self.train_transform(img)
        else:
            img = self.test_transform(img)
        
        label_all = np.zeros((alphabets_length,4))
        for index, a in enumerate(label):
            label_all[:,index] = one_hot_encoding(a)
                
        if self.return_filename:
            return img, filename
        else:
            return img, np.reshape(label_all,-1)
        
    def __len__(self):
        return len(self.data)

#hyperparameter
'''
batch_size = 32

train_data = []
val_data = []

with open(f'{TRAIN_PATH}/annotations.csv', newline='') as csvfile:
    for row in csv.reader(csvfile, delimiter=','):
        if random.random() < 0.8:
            train_data.append(row)
        else:
            val_data.append(row)

train_ds = Task1Dataset(train_data, root=TRAIN_PATH, mode = "train")
train_dl = DataLoader(train_ds, batch_size=batch_size, drop_last=True, shuffle=True)

val_ds = Task1Dataset(val_data, root=TRAIN_PATH,mode = "val")
val_dl = DataLoader(val_ds, batch_size=1, drop_last=False, shuffle=False)

train_ds_2 = Task2Dataset(train_data, root=TRAIN_PATH, mode = "train")
train_dl_2 = DataLoader(train_ds_2, batch_size=batch_size, drop_last=True, shuffle=True)

val_ds_2 = Task2Dataset(val_data, root=TRAIN_PATH,mode = "val")
val_dl_2 = DataLoader(val_ds_2, batch_size=1, drop_last=False, shuffle=False)

train_ds_3 = Task3Dataset(train_data, root=TRAIN_PATH, mode = "train")
train_dl_3 = DataLoader(train_ds_3, batch_size=batch_size, drop_last=True, shuffle=True)

val_ds_3 = Task3Dataset(val_data, root=TRAIN_PATH,mode = "val")
val_dl_3 = DataLoader(val_ds_3, batch_size=1, drop_last=False, shuffle=False)
'''

class ResNet(nn.Module):
    def __init__(self, Layer=18, word_count=1,Pretrained=True):
        super(ResNet, self).__init__()
        self.word_count = word_count
        
        if Layer==18:
            self.classify = nn.Linear(512, alphabets_length * word_count)
        if Layer==50:
            self.classify = nn.Linear(2048, alphabets_length * word_count)
        
        pretrained_model = torchvision.models.__dict__['resnet{}'.format(Layer)](pretrained=Pretrained)
        self.conv1 = pretrained_model._modules['conv1']
        self.bn1 = pretrained_model._modules['bn1']
        self.relu = pretrained_model._modules['relu']
        self.maxpool = pretrained_model._modules['maxpool']

        self.layer1 = pretrained_model._modules['layer1']
        self.layer2 = pretrained_model._modules['layer2']
        self.layer3 = pretrained_model._modules['layer3']
        self.layer4 = pretrained_model._modules['layer4']

        self.avgpool = nn.AdaptiveAvgPool2d(1)

        del pretrained_model

    def forward(self, x):
        x = self.conv1(x)
        x = self.bn1(x)
        x = self.relu(x)
        x = self.maxpool(x)

        x = self.layer1(x)
        x = self.layer2(x)
        x = self.layer3(x)
        x = self.layer4(x)

        x = self.avgpool(x)
        # print(x.shape)
        x = torch.flatten(x,start_dim=1)
        
        x = self.classify(x)

        return x

model = ResNet(Layer=50,word_count=1).to(device)
model.load_state_dict(torch.load(MODEL_PATH, map_location=torch.device(device)))

model_2 = ResNet(Layer=50,word_count=1).to(device)
model_2.load_state_dict(torch.load(MODEL2_PATH, map_location=torch.device(device)))

model_3 = ResNet(Layer=50,word_count=1).to(device)
model_3.load_state_dict(torch.load(MODEL3_PATH, map_location=torch.device(device)))

model_4 = ResNet(Layer=50,word_count=2).to(device)
model_4.load_state_dict(torch.load(MODEL4_PATH, map_location=torch.device(device)))

model_5 = ResNet(Layer=50,word_count=2).to(device)
model_5.load_state_dict(torch.load(MODEL5_PATH, map_location=torch.device(device)))

model_6 = ResNet(Layer=50,word_count=2).to(device)
model_6.load_state_dict(torch.load(MODEL6_PATH, map_location=torch.device(device)))

model_7 = ResNet(Layer=50,word_count=4).to(device)
model_7.load_state_dict(torch.load(MODEL7_PATH, map_location=torch.device(device)))

model_8 = ResNet(Layer=50,word_count=4).to(device)
model_8.load_state_dict(torch.load(MODEL8_PATH, map_location=torch.device(device)))

model_9 = ResNet(Layer=50,word_count=4).to(device)
model_9.load_state_dict(torch.load(MODEL9_PATH, map_location=torch.device(device)))

'''
for epoch in range(1):
    sample_count = 0
    correct_count = 0
    model.eval()
    
    for image, label in val_dl:
        image = image.to(device)
        label = label.to(device)
        
        pred = model(image)
        pred = torch.argmax(pred, dim=1)
        label_argmax = torch.argmax(label, dim=1)

        sample_count += len(image)
        correct_count += (label_argmax == pred)
        
    print("accuracy (validation):", correct_count / sample_count)

for epoch in range(1):
    #pretrained
    sample_count = 0
    correct_count = 0
    
    model_2.eval()
    
    for image, label in val_dl_2:
        image = image.to(device)
        label = label.to(device)
        
        pred = model_2(image)
        
        pred = torch.reshape(pred,(-1,2))
        label = torch.reshape(label,(-1,2))

        label_argmax = torch.argmax(label,dim = 0)
        pred_argmax = torch.argmax(pred,dim = 0)

        sample_count += len(image)
        correct_count += torch.equal(label_argmax,pred_argmax)
        
    print("accuracy (validation):", correct_count / sample_count)

for epoch in range(1):
    #pretrained
    sample_count = 0
    correct_count = 0
    
    model_3.eval()
    
    for image, label in val_dl_3:
        image = image.to(device)
        label = label.to(device)
        
        pred = model_3(image)
        
        pred = torch.reshape(pred,(-1,4))
        label = torch.reshape(label,(-1,4))

        label_argmax = torch.argmax(label,dim = 0)
        pred_argmax = torch.argmax(pred,dim = 0)

        sample_count += len(image)
        correct_count += torch.equal(label_argmax,pred_argmax)
        
    print("accuracy (validation):", correct_count / sample_count)

'''

test_data = []
with open(f'{TEST_PATH}/../sample_submission.csv', newline='') as csvfile:
    for row in csv.reader(csvfile, delimiter=','):
        test_data.append(row)

test_ds = Task1Dataset(test_data, root=TEST_PATH, return_filename=True)
test_dl = DataLoader(test_ds, batch_size=1, drop_last=False, shuffle=False)

test_ds_2 = Task2Dataset(test_data, root=TEST_PATH, return_filename=True)
test_dl_2 = DataLoader(test_ds_2, batch_size=1, drop_last=False, shuffle=False)

test_ds_3 = Task3Dataset(test_data, root=TEST_PATH, return_filename=True)
test_dl_3 = DataLoader(test_ds_3, batch_size=1, drop_last=False, shuffle=False)

if os.path.exists('submission2.csv'):
    myfile = open('submission2.csv', 'a', newline='')
    csv_writer = csv.writer(myfile)
else:
    myfile = open('submission2.csv', 'w', newline='')
    csv_writer = csv.writer(myfile)
    csv_writer.writerow(["filename", "label"])


model.eval()
model_2.eval()
model_3.eval()
model_4.eval()
model_5.eval()
model_6.eval()
model_7.eval()
model_8.eval()
model_9.eval()

for image, filenames in test_dl:
    image = image.to(device)
    
    voting = torch.zeros(3)
    
    pred1 = model(image)
    voting[0] = torch.argmax(pred1, dim=1)
    pred2 = model_2(image)
    voting[1] = torch.argmax(pred2, dim=1)
    pred3 = model_3(image)
    voting[2] = torch.argmax(pred3, dim=1)
    voting = torch.tensor(voting, dtype=torch.int)
    pred_all = torch.argmax(torch.bincount(voting), dim=0)
    
    for i in range(len(filenames)):
        csv_writer.writerow([filenames[i], alphabets[pred_all.item()]])
        myfile.flush()

for image, filenames in test_dl_2:
    image = image.to(device)
    
    voting = torch.zeros((3,2))
    pred4 = model_4(image)
    pred4 = torch.reshape(pred4,(-1,2))
    voting[0] = torch.argmax(pred4, dim=0)
    
    pred5 = model_5(image)
    pred5 = torch.reshape(pred5,(-1,2))
    voting[1] = torch.argmax(pred5, dim=0)
    
    pred6 = model_6(image)
    pred6 = torch.reshape(pred6,(-1,2))
    voting[2] = torch.argmax(pred6, dim=0)
    voting = torch.tensor(voting, dtype=torch.int)
    pred_all1 = torch.argmax(torch.bincount(voting[:,0]), dim=0)
    pred_all2 = torch.argmax(torch.bincount(voting[:,1]), dim=0)

    for i in range(len(filenames)):
        word = alphabets[pred_all1.item()]+alphabets[pred_all2.item()]
        csv_writer.writerow([filenames[i], word ])
        myfile.flush()
        
for image, filenames in test_dl_3:
    image = image.to(device)
    
    voting = torch.zeros((3,4))
    pred7 = model_7(image)
    pred7 = torch.reshape(pred7,(-1,4))
    voting[0] = torch.argmax(pred7, dim=0)
    
    pred8 = model_8(image)
    pred8 = torch.reshape(pred8,(-1,4))
    voting[1] = torch.argmax(pred8, dim=0)
    
    pred9 = model_9(image)
    pred9 = torch.reshape(pred9,(-1,4))
    voting[2] = torch.argmax(pred9, dim=0)
    
    voting = torch.tensor(voting, dtype=torch.int)    
    pred_all1 = torch.argmax(torch.bincount(voting[:,0]), dim=0)
    pred_all2 = torch.argmax(torch.bincount(voting[:,1]), dim=0)
    pred_all3 = torch.argmax(torch.bincount(voting[:,2]), dim=0)
    pred_all4 = torch.argmax(torch.bincount(voting[:,3]), dim=0)
    
    for i in range(len(filenames)):
        word = alphabets[pred_all1.item()]+alphabets[pred_all2.item()]+alphabets[pred_all3.item()]+alphabets[pred_all4.item()]
        csv_writer.writerow([filenames[i], word ])
        myfile.flush()
        
myfile.close()